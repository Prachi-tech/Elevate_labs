# Elevate_labs
Task  given by ElevateLabs in AI ML Internship

# Task 1: Data Cleaning & Preprocessing

### ğŸ¯ Objective:
To clean and prepare raw data for Machine Learning using Python libraries such as Pandas, NumPy, Matplotlib, and Seaborn.

---

## ğŸ› ï¸ Tools & Libraries Used:
- Python
- Pandas
- NumPy
- Seaborn
- Matplotlib
- Scikit-learn (for StandardScaler)

## ğŸ“ Files Included:
- `task1_data_cleaning.ipynb` â€“ Main Jupyter notebook with all code and outputs.
- `README.md` â€“ This file.
- `data/titanic.csv` â€“ Raw dataset.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Task 2: Exploratory Data Analysis (EDA)

ğŸ¯ **Objective**  
To explore and visualize the dataset using Python to gain insights and understand feature relationships.

ğŸ› ï¸ **Tools & Libraries Used**
- Python
- Pandas
- NumPy
- Seaborn
- Matplotlib

ğŸ“Š **Key Steps Performed**
- Analyzed distributions of features (Age, Fare, etc.)
- Explored relationships between features (e.g., Survival vs Sex/Class)
- Plotted heatmaps, histograms, box plots, and count plots
- Identified correlations and patterns in the dataset

ğŸ“ **Files Included**
- `Task2ML_internship.ipynb` â€“ Jupyter notebook with all EDA visualizations
- `Task2_readme.md` â€“ This file
- `Titanic-Dataset.csv` â€“ Raw dataset used for analysis

âœ… **Output**  
Visual insights and statistical summaries to guide feature selection and model building.


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# Task 3: Supervised Machine Learning â€“ Classification

ğŸ¯ **Objective**  
To build and evaluate classification models to predict survival on the Titanic dataset.

ğŸ› ï¸ **Tools & Libraries Used**
- Python
- Pandas
- Scikit-learn
- Matplotlib
- Seaborn

ğŸ“Š **Key Steps Performed**
- Data cleaning and feature engineering
- Split dataset into training and testing sets
- Trained multiple classifiers (e.g., Logistic Regression, Decision Tree)
- Evaluated performance using confusion matrix, accuracy, precision, recall, and F1-score

ğŸ“ **Files Included**
- `Task_3_ML_intership.ipynb` â€“ Jupyter notebook with model building and evaluation
- `Task_3_readme.md` / `Task_3_ML_readme.md` â€“ This file
- `Titanic-Dataset.csv` â€“ Dataset used for training and testing

âœ… **Output**  
Trained classification models with performance metrics and visual evaluation.


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# Task 4: Binary Classification with Logistic Regression

ğŸ¯ **Objective**  
To implement a binary classifier using Logistic Regression on the Breast Cancer Wisconsin dataset.

ğŸ› ï¸ **Tools & Libraries Used**
- Python
- Pandas
- Scikit-learn
- Matplotlib
- StandardScaler (from Scikit-learn)

ğŸ“Š **Key Steps Performed**
- Loaded and cleaned dataset
- Encoded labels and dropped unnecessary columns
- Scaled features using StandardScaler
- Trained logistic regression model
- Evaluated using confusion matrix, precision, recall, F1-score, and ROC-AUC
- Tuned classification threshold to improve recall

ğŸ“ **Files Included**
- `Task_4_ML_.ipynb` â€“ Jupyter notebook with all code and model evaluation
- `Task_4_readme.md` â€“ This file
- `data.csv` â€“ Breast Cancer dataset used for training and testing

âœ… **Output**  
Accurate logistic regression model with ~96% accuracy and ROC-AUC of 1.00, ready for deployment or further analysis.

--------------------------------------------------------------------------------------

Task 5: Decision Trees and Random Forests

ğŸ¯ Objective
To apply tree-based models (Decision Tree and Random Forest) for classification using the Heart Disease dataset.

ğŸ› ï¸ Tools & Libraries Used

Python

Pandas
Scikit-learn
Graphviz
Matplotlib
Seaborn

ğŸ“Š Key Steps Performed

Loaded and explored the heart.csv dataset
Trained a Decision Tree Classifier and visualized the tree
Controlled tree depth to prevent overfitting
Trained a Random Forest Classifier and compared performance
Interpreted feature importances and plotted using Seaborn
Evaluated model using 5-fold cross-validation

ğŸ“ Files Included

task5_ML_internship.ipynb â€“ Jupyter notebook with all code and visualizations
heart.csv â€“ Dataset used for training and testing
README.md â€“ This file

âœ… Output

Pruned Decision Tree Accuracy: 0.80
Random Forest Accuracy: 0.985
Cross-validation Mean Accuracy: ~99.7%
Random Forest model performed with excellent accuracy and generalization
Feature importance helped identify key predictors of heart disease

## ğŸ”— Author:
[Prachi] â€“ B.Tech (IT) | ML Learner |
